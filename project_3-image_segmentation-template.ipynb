{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["VrFCH9hpEyip","UcNIGF4CUCk3","AFHw176FhqQa","uWoVZ_MuKif0","t6tRkdc5HoZT","w_a3OXnSeV0z","RwaY_YcgRayy","pwlVLNJXfUJw","3in1e9BksgIh","RTql4Ftiunfr","ujIVtjsYvxOI","B29jrEvwRqXA","PgLgP04P4-aX","NCQjacybOfqV","3ttl0AK3Hvyh","24qT-sgUO2-d","W0QNbC0YPCKZ","G9HgVWslPGsH","o_5f69nwPtY2","De7VreNxQdct","lpJ3wtyctQJH","BrHQCv7q7LF_","BLT4w0ZfAhlJ","uC2GhaXfA8vC","Mjd9Z3N1ef3I","rjGQ-M02cusP","oK20iNRI3Xxb","KZ9UIdmkfxlA","FzcQQwFuar_7"],"authorship_tag":"ABX9TyO31pbDImFLn1LqrAIyVnyu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#  <font color='#FFE15D'><b>💎 Project 3: Image Segmentation 🔬</b></font>\n","<img src=\"http://dl.howsam.org/Deep-Catalyst/rocket-200px.png\" alt=\"Deep Catalyst\"/>\n","\n","Deep Catalyst Course [webpage](https://howsam.org/downloads/deep-catalyst/)\n","\n","by Howsam AI Academy (www.howsam.org)"],"metadata":{"id":"-uXkcYhkIxS-"}},{"cell_type":"markdown","source":["# 🔴 **Environment Setup**"],"metadata":{"id":"VrFCH9hpEyip"}},{"cell_type":"markdown","source":["## 🟠 The command for connecting Colab to the local host (PC or laptop) is as follows:"],"metadata":{"id":"UcNIGF4CUCk3"}},{"cell_type":"markdown","source":["`jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=4000 --NotebookApp.port_retries=0`"],"metadata":{"id":"G9icRkJ8s8WE"}},{"cell_type":"markdown","source":["## 🟠 Perhaps you may need to install the `torchmetrics` library. To do so, you can execute this cell."],"metadata":{"id":"AFHw176FhqQa"}},{"cell_type":"code","source":["!pip install -q torchmetrics"],"metadata":{"id":"PZsL_K3zhqew"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 🟠 Install `portalocker`"],"metadata":{"id":"uWoVZ_MuKif0"}},{"cell_type":"code","source":["!pip install -q portalocker>=2.0.0"],"metadata":{"id":"TjgdGoWmKYwV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 🟠 Install `wandb`"],"metadata":{"id":"t6tRkdc5HoZT"}},{"cell_type":"code","source":["!pip install wandb"],"metadata":{"id":"nbX6I2IJHoZV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ⚠️ **Don't forget to restart the runtime!**"],"metadata":{"id":"8VgSt9QB6QES"}},{"cell_type":"markdown","source":["# 🔴 **Import Libs**"],"metadata":{"id":"w_a3OXnSeV0z"}},{"cell_type":"code","source":["import os\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torchvision\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","\n","from torch import optim\n","from torch.nn import functional as F\n","\n","import tqdm\n","import torchmetrics as tm"],"metadata":{"id":"vhlVJEkJeTsV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python --version"],"metadata":{"id":"DEzYlyeqTZqQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698053475542,"user_tz":-210,"elapsed":39,"user":{"displayName":"Howsam AI","userId":"08823814227221689123"}},"outputId":"58c6e036-8737-4d44-94d4-f25cfa79c394"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.9.12\n"]}]},{"cell_type":"code","source":["for lib in [np, torch, torchtext, torchvision, tqdm]:\n","  print(lib.__name__, '-->', lib.__version__)"],"metadata":{"id":"6DWjGTq6T8Jg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698053475555,"user_tz":-210,"elapsed":4,"user":{"displayName":"Howsam AI","userId":"08823814227221689123"}},"outputId":"62805731-fae1-44f0-fdbe-b7fb5b5185c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["numpy --> 1.22.0\n","torch --> 1.12.0\n","torchtext --> 0.13.0\n","torchvision --> 0.13.0\n","tqdm --> 4.64.0\n"]}]},{"cell_type":"markdown","source":["# 🔴 **Utils**"],"metadata":{"id":"RwaY_YcgRayy"}},{"cell_type":"code","source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"metadata":{"id":"8yMS7bbmRayz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def num_trainable_params(model):\n","  nums = sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n","  return nums"],"metadata":{"id":"PpKbTUEIRayz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def set_seed(seed):\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  if torch.cuda.is_available():\n","      torch.cuda.manual_seed(seed)\n","      # torch.cuda.manual_seed_all(seed)\n","\n","      # torch.backends.cudnn.deterministic = True\n","      # torch.backends.cudnn.benchmark = False\n"],"metadata":{"id":"6w6sLRLfw398"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 🔴 **Arguments**"],"metadata":{"id":"pwlVLNJXfUJw"}},{"cell_type":"code","source":["seed = 8\n","\n","wandb_enable = False"],"metadata":{"id":"BqPVGv0TfUKE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if wandb_enable:\n","  wandb_arg_name = input('Please input the WandB argument (run) name:')\n","  print(wandb_arg_name)"],"metadata":{"id":"SXOG_oXwrICX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 🟠 Change the font size of the output cells"],"metadata":{"id":"3in1e9BksgIh"}},{"cell_type":"code","source":["print('Salam Howsam!')"],"metadata":{"id":"1_nYkVog8SUR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import HTML\n","shell = get_ipython()\n","\n","def adjust_font_size():\n","  display(HTML('''<style>\n","    body {\n","      font-size: 24px;\n","    }\n","  '''))\n","\n","if adjust_font_size not in shell.events.callbacks['pre_execute']:\n","  shell.events.register('pre_execute', adjust_font_size)"],"metadata":{"id":"BmMM0EfKsSiO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Salam Howsam!')"],"metadata":{"id":"10N1yUE88XRW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 🔴 **Dataset**"],"metadata":{"id":"RTql4Ftiunfr"}},{"cell_type":"markdown","source":["## 🟠 Load the Dataset"],"metadata":{"id":"ujIVtjsYvxOI"}},{"cell_type":"code","source":[],"metadata":{"id":"ShYpXvVzVmP6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 🟠 EDA"],"metadata":{"id":"B29jrEvwRqXA"}},{"cell_type":"code","source":[],"metadata":{"id":"yR8uQsv4E_aJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 🟠 Custom dataset"],"metadata":{"id":"PgLgP04P4-aX"}},{"cell_type":"code","source":[],"metadata":{"id":"o0qUkL0CfQmr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 🟠 Dataloader"],"metadata":{"id":"NCQjacybOfqV"}},{"cell_type":"code","source":[],"metadata":{"id":"KMCJ3UMD0U_f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 🔴 **Model**"],"metadata":{"id":"3ttl0AK3Hvyh"}},{"cell_type":"code","source":[],"metadata":{"id":"2MgBVzorb9oQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 🔴 **Config**"],"metadata":{"id":"24qT-sgUO2-d"}},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"metadata":{"id":"Ma28M5Z36gsq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9ubk3xKaIG6i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if wandb_enable:\n","    key_file = '/content/key'\n","\n","    if os.path.exists(key_file):\n","        with open(key_file) as f:\n","            key = f.readline().strip()\n","        wandb.login(key=key)\n","    else:\n","        print(\"Key file does not exist. Please create the key file with your wandb API key.\")"],"metadata":{"id":"5znK6USrlVd5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 🔴 **Train ➰**"],"metadata":{"id":"W0QNbC0YPCKZ"}},{"cell_type":"markdown","source":["🔰 This is the template for train function, change it if needed."],"metadata":{"id":"yS6EF4HUhi5e"}},{"cell_type":"code","source":["def train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch=None):\n","  model.train()\n","  loss_train = AverageMeter()\n","  metric.reset()\n","\n","  with tqdm.tqdm(train_loader, unit='batch') as tepoch:\n","    for inputs, targets in tepoch:\n","      if epoch:\n","        tepoch.set_description(f'Epoch {epoch}')\n","\n","      inputs = inputs.to(device)\n","      targets = targets.to(device)\n","\n","      outputs = model(inputs)\n","\n","      loss = loss_fn(outputs, targets)\n","\n","      loss.backward()\n","\n","      optimizer.step()\n","      optimizer.zero_grad()\n","\n","      loss_train.update(loss.item(), n=len(targets))\n","      metric.update(outputs, targets)\n","\n","      tepoch.set_postfix(loss=loss_train.avg, metric=metric.compute().item())\n","\n","  return model, loss_train.avg, metric.compute().item()"],"metadata":{"id":"WniOAgk0QyRI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 🔴 **Evaluation**"],"metadata":{"id":"G9HgVWslPGsH"}},{"cell_type":"markdown","source":["🔰 This is the template for evaluation function, change it if needed."],"metadata":{"id":"TsszJ7GVj2l3"}},{"cell_type":"code","source":["def evaluate(model, test_loader, loss_fn, metric):\n","  model.eval()\n","  loss_eval = AverageMeter()\n","  metric.reset()\n","\n","  with torch.inference_mode():\n","    for inputs, targets in test_loader:\n","      inputs = inputs.to(device)\n","      targets = targets.to(device)\n","\n","      outputs = model(inputs)\n","\n","      loss = loss_fn(outputs, targets)\n","      loss_eval.update(loss.item(), n=len(targets))\n","\n","      metric(outputs, targets)\n","\n","  return loss_eval.avg, metric.compute().item()"],"metadata":{"id":"uV0_67_ZQ0xf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 🔴 **Training Process 〽️**"],"metadata":{"id":"o_5f69nwPtY2"}},{"cell_type":"markdown","source":["## 🟠 Finding Hyper-parameters"],"metadata":{"id":"De7VreNxQdct"}},{"cell_type":"markdown","source":["### 🟡 **Step 1:** Calculate the loss for an untrained model using a few batches.\n"],"metadata":{"id":"lpJ3wtyctQJH"}},{"cell_type":"code","source":["model =\n","\n","inputs, targets = next(iter(train_set))\n","inputs = inputs.to(device)\n","targets = targets.to(device)\n","\n","with torch.no_grad():\n","  outputs = model(inputs)\n","  loss = loss_fn(outputs, targets)\n","\n","print(loss)"],"metadata":{"id":"QnE4F4GkzzaR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 🟡 **Step 2:** Try to train and overfit the model on a small subset of the dataset."],"metadata":{"id":"BrHQCv7q7LF_"}},{"cell_type":"code","source":["model =\n","optimizer = torch.optim.SGD(model.parameters(), lr=, momentum=0.9)"],"metadata":{"id":"G0ji0MXsWaPt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kPRZQpPWJ2qv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = ...\n","for epoch in range(num_epochs):\n","  model, _, _ = train_one_epoch(model, ..., loss_fn, optimizer, metric, epoch)"],"metadata":{"id":"bNrg4d9hWaPt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 🟡 **Step 3:** Train the model for a limited number of epochs, experimenting with various learning rates."],"metadata":{"id":"BLT4w0ZfAhlJ"}},{"cell_type":"code","source":["num_epochs =\n","\n","for lr in [...]:\n","  print(f'LR={lr}')\n","\n","  model =\n","  optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=1e-4, momentum=0.9)\n","\n","  for epoch in range(num_epochs):\n","    model, _, _ = train_one_epoch(model, train_set, loss_fn, optimizer, metric, epoch)\n","\n","  print()"],"metadata":{"id":"Jxz5DXoj61mg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 🟡 Step 4: Create a small grid using the weight decay and the best learning rate.\n","\n","\n","\n"],"metadata":{"id":"uC2GhaXfA8vC"}},{"cell_type":"code","source":["num_epochs =\n","\n","for lr in [...]:\n","  for wd in [...]:\n","    print(f'LR={lr}, WD={wd}')\n","\n","    model =\n","    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n","\n","    for epoch in range(num_epochs):\n","      model, loss, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, epoch)\n","\n","    print()"],"metadata":{"id":"a7UeNW3WWaPu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 🟡 Step 5: Train model for longer epochs using the best model from step 4.\n","\n","\n","\n"],"metadata":{"id":"Mjd9Z3N1ef3I"}},{"cell_type":"code","source":["model ="],"metadata":{"id":"IWgkMgC6JWpU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lr =\n","wd =\n","optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9, nesterov=True)"],"metadata":{"id":"YVwLp-02JWpV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_train_hist = []\n","loss_valid_hist = []\n","\n","metric_train_hist = []\n","metric_valid_hist = []\n","\n","best_loss_valid = torch.inf\n","epoch_counter = 0"],"metadata":{"id":"zqxSVVB7JWpW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs =\n","\n","for epoch in range(num_epochs):\n","  # Train\n","  model, loss_train, metric_train = train_one_epoch(model,\n","                                                 train_set,\n","                                                 loss_fn,\n","                                                 optimizer,\n","                                                 metric,\n","                                                 epoch)\n","  # Validation\n","  loss_valid, metric_valid = evaluate(model,\n","                                     valid_set,\n","                                     loss_fn,\n","                                     metric)\n","\n","  loss_train_hist.append(loss_train)\n","  loss_valid_hist.append(loss_valid)\n","\n","  metric_train_hist.append(metric_train)\n","  metric_valid_hist.append(metric_valid)\n","\n","  if loss_valid < best_loss_valid:\n","    torch.save(model, f'model.pt')\n","    best_loss_valid = loss_valid\n","    print('Model Saved!')\n","\n","  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n","  print()\n","\n","  epoch_counter += 1"],"metadata":{"id":"eVqS9SEPJWpW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 🟠 Main Loop"],"metadata":{"id":"rjGQ-M02cusP"}},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"jsWyc30h3mef"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["🔰 Define train dataloader."],"metadata":{"id":"BGRWkn5wm9oP"}},{"cell_type":"code","source":["set_seed(seed)\n","train_loader ="],"metadata":{"id":"uF3H9DeD6TCn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["🔰 Define model."],"metadata":{"id":"4AdYaMU4x34g"}},{"cell_type":"code","source":["set_seed(seed)\n","model ="],"metadata":{"id":"JCtZXDybxexf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["🔰 Define optimizer and Set learning rate and weight decay."],"metadata":{"id":"AUKZRiQPxqrB"}},{"cell_type":"code","source":["set_seed(seed)\n","lr =\n","wd =\n","optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9, nesterov=True)"],"metadata":{"id":"bowjVB5yIXUP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["🔰 Initialize `wandb`"],"metadata":{"id":"iNcyELu78nDo"}},{"cell_type":"code","source":["if wandb_enable:\n","  wandb.init(\n","      project=...,\n","      name=wandb_arg_name,\n","      config={\n","          'lr': lr,\n","          'momentum': momentum,\n","          'batch_size': batch_size,\n","          'seq_len': seq_len,\n","          'hidden_dim': hidden_dim,\n","          'embedding_dim': embedding_dim,\n","          'num_layers': num_layers,\n","          'dropout_embed': dropoute,\n","          'dropout_in_lstm': dropouti,\n","          'dropout_h_lstm': dropouth,\n","          'dropout_out_lstm': dropouto,\n","          'clip': clip,\n","      }\n","  )"],"metadata":{"id":"0yboUzafnGD8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["🔰 Write code to train the model for `num_epochs` epoches."],"metadata":{"id":"AUyFFIzlyaiB"}},{"cell_type":"code","source":["loss_train_hist = []\n","loss_valid_hist = []\n","\n","metric_train_hist = []\n","metric_valid_hist = []\n","\n","best_loss_valid = torch.inf\n","epoch_counter = 0"],"metadata":{"id":"CAXagB4yvtZd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs =\n","\n","for epoch in range(num_epochs):\n","  # Train\n","  model, loss_train, metric_train = train_one_epoch(model,\n","                                                 train_set,\n","                                                 loss_fn,\n","                                                 optimizer,\n","                                                 metric,\n","                                                 epoch)\n","  # Validation\n","  loss_valid, metric_valid = evaluate(model,\n","                                     valid_set,\n","                                     loss_fn,\n","                                     metric)\n","\n","  loss_train_hist.append(loss_train)\n","  loss_valid_hist.append(loss_valid)\n","\n","  metric_train_hist.append(metric_train)\n","  metric_valid_hist.append(metric_valid)\n","\n","  if loss_valid < best_loss_valid:\n","    torch.save(model, f'model.pt')\n","    best_loss_valid = loss_valid\n","    print('Model Saved!')\n","\n","  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n","  print()\n","\n","  if wandb_enable:\n","    wandb.log({\"metric_train\": metric_train, \"loss_train\": loss_train,\n","                \"metric_valid\": metric_valid, \"loss_valid\": loss_valid})\n","\n","  epoch_counter += 1"],"metadata":{"id":"PovABWnU3ld0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wandb.finish()"],"metadata":{"id":"e3LePnZ58uMS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 🟠 Plot"],"metadata":{"id":"oK20iNRI3Xxb"}},{"cell_type":"markdown","source":["🔰 Plot learning curves"],"metadata":{"id":"IKlLvCwuzEAA"}},{"cell_type":"code","source":["plt.figure(figsize=(8, 6))\n","\n","plt.plot(range(epoch_counter), loss_train_hist, 'r-', label='Train')\n","plt.plot(range(epoch_counter), loss_valid_hist, 'b-', label='Validation')\n","\n","plt.xlabel('Epoch')\n","plt.ylabel('loss')\n","plt.grid(True)\n","plt.legend()"],"metadata":{"id":"KYFzTsdIOkVp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 🔴 **Test**"],"metadata":{"id":"KZ9UIdmkfxlA"}},{"cell_type":"markdown","source":["🔰 Test your model using data from the test set"],"metadata":{"id":"SO8iPWH1zVYn"}},{"cell_type":"code","source":[],"metadata":{"id":"35sn67IhKcm_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 🔴 **Segment**"],"metadata":{"id":"FzcQQwFuar_7"}},{"cell_type":"markdown","source":["🔰 Your mission is to write a `segmentation` function and use a test image to see the prediction of the model."],"metadata":{"id":"jh2_9jUp0GF4"}},{"cell_type":"code","source":["model_path = 'model.pt'\n","model = torch.load(model_path)\n","model.eval()"],"metadata":{"id":"pskvb--R-wJ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pVedneOVD6ul"},"execution_count":null,"outputs":[]}]}